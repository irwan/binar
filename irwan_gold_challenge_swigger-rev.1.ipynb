{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e857a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in '/Users/irtea/Documents/MY NB/Project/Data Sains BootCamp/Data/Asset Challenge': ['.DS_Store', 'data 2.csv', 'data.csv', 'README.md', 'citation.bib', 'db_gold_challenge.db', 'datafix.csv', 'new_kamusalay.csv', 'abusive.csv']\n",
      "/Users/irtea/Documents/MY NB/Project/Data Sains BootCamp/Data/Asset Challenge\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:20] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:22] \"GET /docs/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:22] \"\u001b[36mGET /flasgger_static/swagger-ui.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:22] \"\u001b[36mGET /flasgger_static/swagger-ui-bundle.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:22] \"\u001b[36mGET /flasgger_static/swagger-ui-standalone-preset.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:22] \"\u001b[36mGET /flasgger_static/lib/jquery.min.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:23] \"GET /docs.json HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:38] \"POST /text-processing HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:31:40] \"POST /text-processing HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2023 23:32:32] \"POST /text-processing-file HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import demoji\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify\n",
    "from flask import request\n",
    "from flasgger import Swagger, LazyString, LazyJSONEncoder\n",
    "from flasgger import swag_from\n",
    "from flask import Flask, Response, jsonify\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "files = os.listdir(cwd)\n",
    "print(\"Files in %r: %s\" %(cwd, files))\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "#membaca file csv abusive dan kamus alay\n",
    "\n",
    "%cd '/Users/irtea/Documents/MY NB/Project/Data Sains BootCamp/Data/Asset Challenge'\n",
    "df_abusive = pd.read_csv('abusive.csv')\n",
    "df_alay = pd.read_csv('new_kamusalay.csv',encoding= 'latin-1')\n",
    "\n",
    "\n",
    "#mengeksport data abusive dan kamus alay ke database\n",
    "\n",
    "connection=sqlite3.connect('db_gold_challenge.db')\n",
    "cursorObj = connection.cursor()\n",
    "df_abusive.to_sql(name='tb_abusive_ir1', con=connection, index=False, if_exists='replace')\n",
    "df_alay.to_sql(name='tb_alay_ir1', con=connection, index=False, if_exists='replace')\n",
    "\n",
    "data_abusive = pd.read_sql_query ('''select * from tb_abusive_ir1''',connection)\n",
    "data_alay = pd.read_sql_query ('''select * from tb_alay_ir1''',connection)\n",
    "\n",
    "#menyimpan data hasil cleansing ke Database\n",
    "\n",
    "cursorObj.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS data_input (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        original_text TEXT,\n",
    "        clean_text TEXT\n",
    "    )\n",
    "''')\n",
    "connection.commit()\n",
    "\n",
    "#  FUnction cleansing\n",
    "\n",
    "def cleansing(sent):\n",
    "       \n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]',' ', string)\n",
    "    string = re.sub(r'http\\S+', '', string)  \n",
    "    string = re.sub(r'[^\\x00-\\x7f]',r'', string)\n",
    "    string = re.sub('\\?', '', string)\n",
    "    string = string.replace('/na', '')\n",
    "    string = re.sub(r'www\\.[^ ]+', '', string)\n",
    "    string = re.sub(r'[^a-zA-Z0-9\\s]', '', string)\n",
    "    string = re.sub(r'\\b(\\w+)\\b\\s+\\b\\1\\b', r'\\1', string)\n",
    "    string = re.sub(r'(\\w)(\\1{2,})', r\"\\1\", string)\n",
    "    string = re.sub(r\"\\b[a-zA-Z]\\b\",\"\",string)\n",
    "    string = re.sub('(s{2,})',' ',string)\n",
    "    string = demoji.replace(string, '')\n",
    "    string = string.strip()\n",
    "\n",
    "    characters_to_remove = ['xf0', 'x9f', 'x8f', 'xe2', 'x80', 'x9c', 'x84', 'xa3', 'x98', 'x86',\n",
    "                        'xc2', 'xb2', 'x9d', 'xa4', 'xa2', 'x99', 'xab', 'xaa', 'xe1',\n",
    "                        'xbd', 'xcf', 'xaa', 'xce', 'xb5', 'xcf', 'x81', 'xce', 'xb7',\n",
    "                        'xb1', 'xaf', 'xc4', 'x93', 'x82', 'xd', 'url','x8e', 'xb6', 'x8e', 'xa7', 'xa5', 'x8d', 'xba',\n",
    "                        'x91', 'x8c', 'x88', 'x94', 'x85', 'xa6', 'x91', 'xa', 'x92', 'x89', 'xad',\n",
    "                        'xb3', 'xd0', 'xbc', 'xd1', 'xc6', 'xd0', 'xbcs', 'xa6', 'x83', 'x9b',\n",
    "                        'xac', 'xef', 'xbc', 'xef', 'xa5', 'xe0', 'xb8', 'xb4', 'x8c', 'xef', 'xa5', 'xe0', 'xb8', 'xb4', 'xef', 'xbc']\n",
    "        \n",
    "    for char_sequence in characters_to_remove:\n",
    "        string = string.replace(char_sequence, '')\n",
    "        \n",
    "    string = re.sub(\"(username|user|url|rt|xf|fx|xe|xa)\\s|\\s(user|url|rt|xf|fx|xe|xa)\",\"\",string)\n",
    "        \n",
    "    return string\n",
    "\n",
    "\n",
    "# Function replace alay\n",
    "\n",
    "database_alay = dict(zip(data_alay['kata_alay'], data_alay['kata_baku']))\n",
    "\n",
    "def replace_alay(text, database_alay, compiled_alay_patterns):\n",
    "    for alay_pattern, baku_word in zip(compiled_alay_patterns, database_alay.values()):\n",
    "        text = alay_pattern.sub(baku_word, text)\n",
    "    return text\n",
    "\n",
    "compiled_alay_patterns = [re.compile(rf'\\b{re.escape(alay_word)}\\b', flags=re.IGNORECASE) for alay_word in database_alay.keys()]\n",
    "\n",
    "\n",
    "# Function Sensor Abusive\n",
    "\n",
    "database_kata_kasar = set(data_abusive['ABUSIVE'])\n",
    "\n",
    "def sensor_kalimat(teks, database_kata_kasar):\n",
    "    kata_kata = teks.split()\n",
    "    kata_kata_bersih = [kata if kata.lower() not in database_kata_kasar else '*' * len(kata) for kata in kata_kata]\n",
    "    kalimat_bersih = ' '.join(kata_kata_bersih)\n",
    "    return kalimat_bersih\n",
    "\n",
    "\n",
    "app.json_encoder = LazyJSONEncoder\n",
    "swagger_template = {\n",
    "    \"info\": {\n",
    "        \"title\":  \"API Documentation for Data Processing and Modeling\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"Dokumentasi API untuk Data Processing dan Modeling Tugas Gold Challenge an Irwan\"\n",
    "    },\n",
    "    \"host\": \"127.0.0.1:5000\"\n",
    "}\n",
    "\n",
    "swagger_config = {\n",
    "    \"headers\": [],\n",
    "    \"specs\": [\n",
    "        {\n",
    "            \"endpoint\": 'docs',\n",
    "            \"route\": '/docs.json',\n",
    "        }\n",
    "    ],\n",
    "    \"static_url_path\": \"/flasgger_static\",\n",
    "    \"swagger_ui\": True,\n",
    "    \"specs_route\": \"/docs/\"\n",
    "}\n",
    "\n",
    "\n",
    "swagger = Swagger(app, template=swagger_template,             \n",
    "                  config=swagger_config)\n",
    "\n",
    "@swag_from(\"/Users/irtea/Documents/MY NB/Project/Data Sains BootCamp/Data/docs/hello_world.yml\", methods=['GET'])\n",
    "@app.route('/', methods=['GET'])\n",
    "def hello_world():\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Menyapa Hello World\",\n",
    "        'data': \"Hello World\",\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "\n",
    "@swag_from(\"/Users/irtea/Documents/MY NB/Project/Data Sains BootCamp/Data/docs/text_processing.yml\", methods=['POST'])\n",
    "@app.route('/text-processing', methods=['POST'])\n",
    "def text_processing():\n",
    "\n",
    "    \n",
    "    text = request.form.get('text')\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses cleansing\n",
    "    \n",
    "    text_cleansing = cleansing(text)\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses mengganti kata alay\n",
    "\n",
    "\n",
    "    text_cleansing_alay = replace_alay(text_cleansing, database_alay, compiled_alay_patterns)\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses sensor kata abusive\n",
    "\n",
    "\n",
    "    text_cleansing_alay_sensor = sensor_kalimat(text_cleansing_alay, database_kata_kasar)\n",
    "\n",
    "    \n",
    "    # menyimpan hasil cleansing ke database \n",
    "    \n",
    "    entities = (text, text_cleansing_alay_sensor)\n",
    "    connection=sqlite3.connect('db_gold_challenge.db')\n",
    "    cursorObj = connection.cursor()\n",
    "    cursorObj.execute('''\n",
    "        INSERT INTO data_input (original_text, clean_text)\n",
    "        VALUES (?, ?)\n",
    "    ''', entities)\n",
    "    connection.commit()\n",
    "        \n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Teks yang sudah diproses cleansing dan sensor abusive\",\n",
    "        'data': text_cleansing_alay_sensor,\n",
    "    }\n",
    " \n",
    "    \n",
    "    response_data = jsonify(json_response)\n",
    "    \n",
    "#     connection.close()\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "\n",
    "\n",
    "@swag_from(\"/Users/irtea/Documents/MY NB/Project/Data Sains BootCamp/Data/docs/text_processing_file.yml\", methods=['POST'])\n",
    "@app.route('/text-processing-file', methods=['POST'])\n",
    "def text_processing_file():\n",
    "\n",
    "    # Upladed file\n",
    "    file = request.files.getlist('file')[0]\n",
    "\n",
    "    # Import file csv ke Pandas\n",
    "    df = pd.read_csv(file, encoding='latin1')\n",
    "    \n",
    "    #verifikasi data tweet apakah available \n",
    "    \n",
    "    if 'Tweet' not in df.columns:\n",
    "        raise ValueError('Column \"Tweet\" not found')\n",
    "        \n",
    "    # menghapus data yang duplicate\n",
    "#     df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    # Ambil teks yang akan diproses dalam format list\n",
    "    texts = df['Tweet'].to_list()\n",
    "\n",
    "    # Lakukan cleansing pada teks\n",
    "    \n",
    "    df['Tweet clean'] = df['Tweet'].apply(cleansing)\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses mengganti kata alay\n",
    "\n",
    "    df['Tweet replace alay'] = df['Tweet clean'].apply(lambda tweet: replace_alay(tweet, database_alay, compiled_alay_patterns))\n",
    "\n",
    "    \n",
    "    # Menjalankan proses sensor kata abusive\n",
    "\n",
    "\n",
    "    df['Tweet sensor abusive'] = df['Tweet replace alay'].apply(lambda tweet: sensor_kalimat(tweet, database_kata_kasar))\n",
    "\n",
    "    \n",
    "    # menyimpan data ke database\n",
    "    connection=sqlite3.connect('db_gold_challenge.db')\n",
    "    cursorObj = connection.cursor()\n",
    "    kolom_yang_diekspor = ['Tweet', 'Tweet sensor abusive']\n",
    "    df_subset = df[kolom_yang_diekspor]\n",
    "    df_subset.to_sql(name='tb_data_file_ir', con=connection, index=False, if_exists='replace')\n",
    "   \n",
    "    # mengubah data ke json\n",
    "    \n",
    "    cursor = connection.execute(\"SELECT * FROM tb_data_file_ir\")\n",
    "    data = cursor.fetchall()\n",
    "    \n",
    "    json_data = []\n",
    "    for row in data:\n",
    "        json_data.append( row[1]) #urutan kolom data tweet yang telah dicleansing\n",
    "        \n",
    "    \n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"File yang sudah diproses cleansing dan sensor abusive\",\n",
    "        'data': json_data,\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    \n",
    "#     connection.close()\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121fc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
